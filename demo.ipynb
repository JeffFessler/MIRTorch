{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from mirtorch.prox import prox\n",
    "from mirtorch.linear import *\n",
    "from mirtorch.alg import *\n",
    "from mirtorch.alg.fista import FISTA\n",
    "import numpy as np\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import normalize\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70000\n",
      "7141\n",
      "6313\n",
      "13454\n"
     ]
    }
   ],
   "source": [
    "#Binary classification on MNIST digits using FISTA (specifically 3 and 5)\n",
    "#get dataset\n",
    "try:\n",
    "    X,y = X_orig, y_orig\n",
    "except:\n",
    "    X, y = fetch_openml('mnist_784', version=1, return_X_y=True, as_frame=False)\n",
    "\n",
    "y = y.astype(np.float64)\n",
    "X_orig, y_orig = X, y\n",
    "print(len(X))\n",
    "print(len(X[y==3]))\n",
    "print(len(X[y==5]))\n",
    "print(len(X[(y==3) | (y==5)]))\n",
    "\n",
    "def show_digit(X, y):\n",
    "    digit_image = X.reshape(28,28)\n",
    "    print(f'Expected digit {y+4}')\n",
    "    plt.imshow(digit_image, cmap=matplotlib.cm.binary, interpolation=\"nearest\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13454, 784) (13454,)\n",
      "Expected digit 5.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#reduce data to be binary classification for simplicity\n",
    "X, y = X[(y==3) | (y==5)], y[(y==3) | (y==5)]\n",
    "y = y - 4\n",
    "print(X.shape, y.shape)\n",
    "show_digit(X[0], y[0])\n",
    "#create train/test sets\n",
    "X = normalize(X, axis=0)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=10000, test_size=3454)\n",
    "X_train, X_test, y_train, y_test = torch.from_numpy(X_train), torch.from_numpy(X_test), torch.from_numpy(y_train), torch.from_numpy(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.type(torch.double)\n",
    "X_test = X_test.type(torch.double)\n",
    "y_train = y_train.type(torch.double)\n",
    "y_test = y_test.type(torch.double)\n",
    "\n",
    "def diff_huberhinge_grad(x, deltah = .1):\n",
    "    result = torch.where(x>=1, torch.tensor([0],dtype=torch.double), \n",
    "                         torch.where(x<=1-deltah, torch.tensor([-1],dtype=torch.double), (x-1)/deltah))\n",
    "    return result\n",
    "\n",
    "class A(LinearMap):\n",
    "    def __init__(self, apply_y = True):\n",
    "        self._A = X_train.clone()\n",
    "        if apply_y:\n",
    "            for i in range(self._A.shape[0]):\n",
    "                self._A[i] *= y_train[i]\n",
    "        \n",
    "        super().__init__([28*28], [10000])\n",
    "        \n",
    "    def _apply(self, x):\n",
    "        return torch.matmul(self._A, x)\n",
    "    \n",
    "    def _apply_adjoint(self, x):\n",
    "        return torch.matmul(self._A.T, x)\n",
    "        \n",
    "class grad:\n",
    "    def __init__(self, dh=.1):\n",
    "        self.a = A()\n",
    "        self.deltah = dh\n",
    "        \n",
    "    def __call__(self, x):\n",
    "        x = self.a(x)\n",
    "        x = diff_huberhinge_grad(x)\n",
    "        x = self.a.adjoint(x)\n",
    "        return x\n",
    "    \n",
    "def eval(x):\n",
    "    res = torch.matmul(X_test, x)\n",
    "    res = torch.sign(res)\n",
    "    res *= y_test\n",
    "    total = res.shape[0]\n",
    "    correct = res[res>0].shape[0]\n",
    "    print(f'\\tCorrect {correct} out of {total} total, percentage: {correct/total}')\n",
    "    return correct, total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tCorrect 3296 out of 3454 total, percentage: 0.9542559351476549\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f9406096160>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = torch.zeros(28*28, dtype=torch.double, requires_grad=True)\n",
    "grad_ = grad()\n",
    "L = 1/grad_.deltah * torch.linalg.norm(grad_.a._A, float('inf')) * torch.linalg.norm(grad_.a._A, 1)\n",
    "prox_ = prox.L1Regularizer(.0001)\n",
    "res = FISTA(max_iter=300, fgrad=grad_, Lf=L, prox=prox_).run_alg(x)\n",
    "eval(res)\n",
    "res.sum().backward() #can run .backward() on this\n",
    "#look at grad of result with respect to starting input\n",
    "plt.imshow(x.grad.data.reshape(28,28).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "residual at 1th iter: 130151.10287963005\n",
      "residual at 2th iter: 7761.52935015468\n",
      "residual at 3th iter: 2452.6380651158106\n",
      "residual at 4th iter: 963.8992040061985\n",
      "residual at 5th iter: 393.1200153970831\n",
      "residual at 6th iter: 316.6854813521478\n",
      "residual at 7th iter: 148.59014930867937\n",
      "residual at 8th iter: 91.72921030685653\n",
      "residual at 9th iter: 63.018407054198725\n",
      "residual at 10th iter: 49.15001098141681\n",
      "residual at 11th iter: 35.952865057856755\n",
      "residual at 12th iter: 21.81566399968476\n",
      "residual at 13th iter: 268.29231579336613\n",
      "residual at 14th iter: 20.069491360269588\n",
      "residual at 15th iter: 13.588715858625568\n",
      "residual at 16th iter: 11.739099067654713\n",
      "residual at 17th iter: 8.21867508417376\n",
      "residual at 18th iter: 10.422624026210514\n",
      "residual at 19th iter: 8.457904707629643\n",
      "residual at 20th iter: 6.587085891943401\n",
      "residual at 21th iter: 5.921871168658417\n",
      "residual at 22th iter: 5.715179842368026\n",
      "residual at 23th iter: 38.30267280033651\n",
      "residual at 24th iter: 27.55632439425942\n",
      "residual at 25th iter: 4.069704622280445\n",
      "residual at 26th iter: 3.109114053970787\n",
      "residual at 27th iter: 2.919908439432634\n",
      "residual at 28th iter: 2.434035329964604\n",
      "residual at 29th iter: 2.644452152109397\n",
      "residual at 30th iter: 5.921657981748773\n",
      "residual at 31th iter: 1.5007025478943288\n",
      "residual at 32th iter: 1.6671718226523724\n",
      "residual at 33th iter: 1.3039429586691238\n",
      "residual at 34th iter: 3.1765552412328306\n",
      "residual at 35th iter: 12.609562402782874\n",
      "residual at 36th iter: 1.4257799203780492\n",
      "residual at 37th iter: 0.9489917253725431\n",
      "residual at 38th iter: 0.6282624714412345\n",
      "residual at 39th iter: 0.6697176708582079\n",
      "residual at 40th iter: 0.5850361077225004\n",
      "residual at 41th iter: 1.2476224638023923\n",
      "residual at 42th iter: 0.6058517966760554\n",
      "residual at 43th iter: 0.7939043467365146\n",
      "residual at 44th iter: 0.6025044871795997\n",
      "residual at 45th iter: 4.0808423443741155\n",
      "residual at 46th iter: 0.47431506283596236\n",
      "residual at 47th iter: 0.3704971897381212\n",
      "residual at 48th iter: 0.43265906074310384\n",
      "residual at 49th iter: 0.3541382074691925\n",
      "residual at 50th iter: 0.22317528177720108\n",
      "residual at 51th iter: 0.22940852284809887\n",
      "residual at 52th iter: 0.2206320234592622\n",
      "residual at 53th iter: 0.3395416829823974\n",
      "residual at 54th iter: 0.3079602834885561\n",
      "residual at 55th iter: 0.6819844173320548\n",
      "residual at 56th iter: 0.19373175848557997\n",
      "residual at 57th iter: 0.1281700775441923\n",
      "residual at 58th iter: 0.14191737923333925\n",
      "residual at 59th iter: 0.20834202221311987\n",
      "residual at 60th iter: 0.23667496442000388\n",
      "residual at 61th iter: 0.25111812429513203\n",
      "residual at 62th iter: 0.17978980868863453\n",
      "residual at 63th iter: 0.1133215784733834\n",
      "residual at 64th iter: 0.06249026519992507\n",
      "residual at 65th iter: 0.0723685795025292\n",
      "residual at 66th iter: 0.4564065884928591\n",
      "residual at 67th iter: 0.06421095488981264\n",
      "residual at 68th iter: 0.05558580026683636\n",
      "residual at 69th iter: 0.06975111448216657\n",
      "residual at 70th iter: 0.042844140576662894\n",
      "residual at 71th iter: 0.05296003454223969\n",
      "residual at 72th iter: 0.06677965580323277\n",
      "residual at 73th iter: 0.03241387324640446\n",
      "residual at 74th iter: 0.026748518361529337\n",
      "residual at 75th iter: 0.15160763115286283\n",
      "residual at 76th iter: 0.33809244087019863\n",
      "residual at 77th iter: 0.029813064842499636\n",
      "residual at 78th iter: 0.13190606588348924\n",
      "residual at 79th iter: 0.0700951429735065\n",
      "residual at 80th iter: 0.02915129794626329\n",
      "residual at 81th iter: 0.02269464893949296\n",
      "residual at 82th iter: 0.020465066649968902\n",
      "residual at 83th iter: 0.022102276579079\n",
      "residual at 84th iter: 0.02356848189903692\n",
      "residual at 85th iter: 0.04265660780173102\n",
      "residual at 86th iter: 0.13181463802247328\n",
      "residual at 87th iter: 0.05002461233528816\n",
      "residual at 88th iter: 0.021576644791414967\n",
      "residual at 89th iter: 0.03300449816526192\n",
      "residual at 90th iter: 0.018655718698618085\n",
      "residual at 91th iter: 0.017575585630918766\n",
      "residual at 92th iter: 0.014775051779976015\n",
      "residual at 93th iter: 0.01471576906414689\n",
      "residual at 94th iter: 0.017977542574087096\n",
      "residual at 95th iter: 0.026981698951078596\n",
      "residual at 96th iter: 0.048144641105536026\n",
      "residual at 97th iter: 0.01316343519048053\n",
      "residual at 98th iter: 0.012332688179844202\n",
      "residual at 99th iter: 0.05421553060778814\n",
      "residual at 100th iter: 0.014059831144172752\n",
      "residual at 101th iter: 0.016276190385012376\n",
      "residual at 102th iter: 0.009659734564058178\n",
      "residual at 103th iter: 0.019828789677958036\n",
      "residual at 104th iter: 0.009273121175543698\n",
      "residual at 105th iter: 0.007631234506017018\n",
      "residual at 106th iter: 0.18907643823388465\n",
      "residual at 107th iter: 0.012897597929914939\n",
      "residual at 108th iter: 0.008072028254011484\n",
      "residual at 109th iter: 0.023369496805748673\n",
      "residual at 110th iter: 0.006444087313026137\n",
      "residual at 111th iter: 0.016100943819653116\n",
      "residual at 112th iter: 0.006522145920315293\n",
      "residual at 113th iter: 0.03346927349845864\n",
      "residual at 114th iter: 0.004578479839482589\n",
      "residual at 115th iter: 0.011030692020705581\n",
      "residual at 116th iter: 0.010396626456978385\n",
      "residual at 117th iter: 0.013206392907436137\n",
      "residual at 118th iter: 0.007430476118854947\n",
      "residual at 119th iter: 0.0053042739907783725\n",
      "residual at 120th iter: 0.005038743934069328\n",
      "residual at 121th iter: 0.007879334214400173\n",
      "residual at 122th iter: 0.009759991233571842\n",
      "residual at 123th iter: 0.010841879719503142\n",
      "residual at 124th iter: 0.005268052062797066\n",
      "residual at 125th iter: 0.006892743964150558\n",
      "residual at 126th iter: 0.005052194403334161\n",
      "residual at 127th iter: 0.020582256270776214\n",
      "residual at 128th iter: 0.003134107309549788\n",
      "residual at 129th iter: 0.0050776012500955685\n",
      "residual at 130th iter: 0.0041160847590291615\n",
      "residual at 131th iter: 0.01828034341738871\n",
      "residual at 132th iter: 0.002434689190602868\n",
      "residual at 133th iter: 0.00262417409912675\n",
      "residual at 134th iter: 0.0035970549583661973\n",
      "residual at 135th iter: 0.006268061728780043\n",
      "residual at 136th iter: 0.02228808210259292\n",
      "residual at 137th iter: 0.008201461328268883\n",
      "residual at 138th iter: 0.0023409388345882387\n",
      "residual at 139th iter: 0.0017144667883777038\n",
      "residual at 140th iter: 0.003243452595669517\n",
      "residual at 141th iter: 0.001871594047143758\n",
      "residual at 142th iter: 0.001724915661446751\n",
      "residual at 143th iter: 0.007959233688337692\n",
      "residual at 144th iter: 0.004278871700185099\n",
      "residual at 145th iter: 0.004140638540510219\n",
      "residual at 146th iter: 0.017947141295322454\n",
      "residual at 147th iter: 0.0029991625679611665\n",
      "residual at 148th iter: 0.002621773291180227\n",
      "residual at 149th iter: 0.004845106683309286\n",
      "residual at 150th iter: 0.0037184900858006765\n",
      "residual at 151th iter: 0.002182825675636505\n",
      "residual at 152th iter: 0.0029234921761261247\n",
      "residual at 153th iter: 0.001844368851370563\n",
      "residual at 154th iter: 0.003292725480601725\n",
      "residual at 155th iter: 0.0023123204379528963\n",
      "residual at 156th iter: 0.009324172826495225\n",
      "residual at 157th iter: 0.006029352575473502\n",
      "residual at 158th iter: 0.0018225398844804188\n",
      "residual at 159th iter: 0.002076094569538749\n",
      "residual at 160th iter: 0.0034232612348801244\n",
      "residual at 161th iter: 0.0035729575769425483\n",
      "residual at 162th iter: 0.001658688316059523\n",
      "residual at 163th iter: 0.001448088714823503\n",
      "residual at 164th iter: 0.002454952918619388\n",
      "residual at 165th iter: 0.007808557179834536\n",
      "residual at 166th iter: 0.0063266213640207035\n",
      "residual at 167th iter: 0.0027553573316104886\n",
      "residual at 168th iter: 0.0024946362097333797\n",
      "residual at 169th iter: 0.004150110645508579\n",
      "residual at 170th iter: 0.00273078226188198\n",
      "residual at 171th iter: 0.001285690795675624\n",
      "residual at 172th iter: 0.002517799949696688\n",
      "residual at 173th iter: 0.0018922067240256851\n",
      "residual at 174th iter: 0.0014468702535219416\n",
      "residual at 175th iter: 0.03723514705550025\n",
      "residual at 176th iter: 0.0019250433554376157\n",
      "residual at 177th iter: 0.0015873173530531995\n",
      "residual at 178th iter: 0.001391003209181489\n",
      "residual at 179th iter: 0.0023630383351327796\n",
      "residual at 180th iter: 0.002710701581681024\n",
      "residual at 181th iter: 0.0012454491502012443\n",
      "residual at 182th iter: 0.004972320385427003\n",
      "residual at 183th iter: 0.0014597602313415133\n",
      "residual at 184th iter: 0.001857881525888247\n",
      "residual at 185th iter: 0.007556925400542123\n",
      "residual at 186th iter: 0.0028723325459631055\n",
      "residual at 187th iter: 0.00092008174414727\n",
      "residual at 188th iter: 0.002002764711414827\n",
      "residual at 189th iter: 0.0008659744519825687\n",
      "residual at 190th iter: 0.003101627772204741\n",
      "residual at 191th iter: 0.0006724088718533218\n",
      "residual at 192th iter: 0.002491286541887446\n",
      "residual at 193th iter: 0.0008379239643794089\n",
      "residual at 194th iter: 0.001156719102851676\n",
      "residual at 195th iter: 0.014164550736942191\n",
      "residual at 196th iter: 0.0013805924620490036\n",
      "residual at 197th iter: 0.0006266655613922529\n",
      "residual at 198th iter: 0.0005715222990000808\n",
      "residual at 199th iter: 0.0006929426453539778\n",
      "residual at 200th iter: 0.0005966983364910082\n",
      "residual at 201th iter: 0.0006862535816796332\n",
      "residual at 202th iter: 0.00031088354563538185\n",
      "residual at 203th iter: 0.000544079814854775\n",
      "residual at 204th iter: 0.001961964499500275\n",
      "residual at 205th iter: 0.000431159986860464\n",
      "residual at 206th iter: 0.0005082926336562034\n",
      "residual at 207th iter: 0.00030639635591498646\n",
      "residual at 208th iter: 0.000795175364588354\n",
      "residual at 209th iter: 0.00039807004237869467\n",
      "residual at 210th iter: 0.00023541465730619556\n",
      "residual at 211th iter: 0.00044522725884905376\n",
      "residual at 212th iter: 0.0002351564324061495\n",
      "residual at 213th iter: 0.0006540244462740887\n",
      "residual at 214th iter: 0.003099079811536128\n",
      "residual at 215th iter: 0.0005982638858583261\n",
      "residual at 216th iter: 0.00037669907750381834\n",
      "residual at 217th iter: 0.00022474895576696238\n",
      "residual at 218th iter: 0.00024128217920421508\n",
      "residual at 219th iter: 0.0004925966188018905\n",
      "residual at 220th iter: 0.00037340560950662274\n",
      "residual at 221th iter: 0.0002006170868973513\n",
      "residual at 222th iter: 0.0001625735490370958\n",
      "residual at 223th iter: 0.0001993429532878786\n",
      "residual at 224th iter: 0.00089870584148236\n",
      "residual at 225th iter: 0.00023881759544434452\n",
      "residual at 226th iter: 0.000382939415459082\n",
      "residual at 227th iter: 0.00018337914373392418\n",
      "residual at 228th iter: 0.00017794707049864395\n",
      "residual at 229th iter: 0.00014426333611640017\n",
      "residual at 230th iter: 0.00013489079480405984\n",
      "residual at 231th iter: 0.00013471349467289413\n",
      "residual at 232th iter: 0.0002150703307705623\n",
      "residual at 233th iter: 0.0002119959555460444\n",
      "residual at 234th iter: 0.0006935030999566109\n",
      "residual at 235th iter: 0.0001705149934387189\n",
      "residual at 236th iter: 0.000299808241073248\n",
      "residual at 237th iter: 0.00017885306921694075\n",
      "residual at 238th iter: 0.0003111773853371702\n",
      "residual at 239th iter: 0.00024834755941909904\n",
      "residual at 240th iter: 0.0004151346485909013\n",
      "residual at 241th iter: 0.0002448150984446682\n",
      "residual at 242th iter: 0.000123433735963124\n",
      "residual at 243th iter: 0.00025946423051474\n",
      "residual at 244th iter: 0.0017872182542779077\n",
      "residual at 245th iter: 0.00016958648170613174\n",
      "residual at 246th iter: 0.00016798235728014143\n",
      "residual at 247th iter: 0.00041246171424044113\n",
      "residual at 248th iter: 0.0007642255112837758\n",
      "residual at 249th iter: 0.00027915188002687965\n",
      "residual at 250th iter: 0.0003530599646787361\n",
      "residual at 251th iter: 0.0003936613544285746\n",
      "residual at 252th iter: 0.000435108653907876\n",
      "residual at 253th iter: 0.00860582466710725\n",
      "residual at 254th iter: 0.0005591252023408862\n",
      "residual at 255th iter: 0.00038388970633212993\n",
      "residual at 256th iter: 0.0006239165901025231\n",
      "residual at 257th iter: 0.0007476974499023782\n",
      "residual at 258th iter: 0.0009350986444646632\n",
      "residual at 259th iter: 0.0004500746360359876\n",
      "residual at 260th iter: 0.0006124171642582178\n",
      "residual at 261th iter: 0.00030144953894099466\n",
      "residual at 262th iter: 0.002179470209561907\n",
      "residual at 263th iter: 0.005706828030398748\n",
      "residual at 264th iter: 0.00045483696153920955\n",
      "residual at 265th iter: 0.0009616789918603728\n",
      "residual at 266th iter: 0.0008825867984619861\n",
      "residual at 267th iter: 0.0007181835175224275\n",
      "residual at 268th iter: 0.000707645348140222\n",
      "residual at 269th iter: 0.00048520980433793296\n",
      "residual at 270th iter: 0.00293475470259827\n",
      "residual at 271th iter: 0.001190777802046566\n",
      "residual at 272th iter: 0.0005891883572669101\n",
      "residual at 273th iter: 0.006111658842634375\n",
      "residual at 274th iter: 0.0010449157859179397\n",
      "residual at 275th iter: 0.0005988060564409885\n",
      "residual at 276th iter: 0.0005981184172444666\n",
      "residual at 277th iter: 0.0012450530172817467\n",
      "residual at 278th iter: 0.0004959945482507444\n",
      "residual at 279th iter: 0.0013665436840180985\n",
      "residual at 280th iter: 0.0010172193607887025\n",
      "residual at 281th iter: 0.001591018051347026\n",
      "residual at 282th iter: 0.002022174049645424\n",
      "residual at 283th iter: 0.007192606552239529\n",
      "residual at 284th iter: 0.00110583617327989\n",
      "residual at 285th iter: 0.001244518455078592\n",
      "residual at 286th iter: 0.0010655611934043017\n",
      "residual at 287th iter: 0.001181721720073252\n",
      "residual at 288th iter: 0.0012521759272418522\n",
      "residual at 289th iter: 0.003107114526681016\n",
      "residual at 290th iter: 0.0008961897751884095\n",
      "residual at 291th iter: 0.0005051183505181314\n",
      "residual at 292th iter: 0.00048140936448975416\n",
      "residual at 293th iter: 0.001729536407328039\n",
      "residual at 294th iter: 0.0072933615896581105\n",
      "residual at 295th iter: 0.0008281607932760133\n",
      "residual at 296th iter: 0.0011352028989121583\n",
      "residual at 297th iter: 0.0006017676855644795\n",
      "residual at 298th iter: 0.0005500338412564371\n",
      "residual at 299th iter: 0.0004752314301051571\n",
      "residual at 300th iter: 0.0006268292099705185\n"
     ]
    }
   ],
   "source": [
    "a_mat = A(apply_y=False)\n",
    "x = torch.zeros(28*28, dtype=torch.double, requires_grad=True)\n",
    "res = CG(A=a_mat.H*a_mat, max_iter=300).run(x0=x, b=a_mat.H(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tCorrect 3290 out of 3454 total, percentage: 0.952518818760857\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3290, 3454)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval(res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit (conda)",
   "language": "python",
   "name": "python38564bitcondac7010d5495f04ec788964219d36e608d"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
