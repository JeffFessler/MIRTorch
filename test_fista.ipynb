{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from mirtorch.prox import prox\n",
    "from mirtorch.linear import *\n",
    "import numpy as np\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initial implementation\n",
    "class FISTA():\n",
    "    def __init__(self, max_iter, step, fval, grad, prox, momentum = 1, restart = False):\n",
    "        self.max_iter = max_iter\n",
    "        self.step = step\n",
    "        self.fval = fval\n",
    "        self.grad = grad\n",
    "        self.prox = prox\n",
    "        self.momentum = momentum\n",
    "        self.restart = restart\n",
    "    '''\n",
    "    Experimenting different implementation\n",
    "    '''\n",
    "    def _update(self):\n",
    "        #looks like one possible implementation from jeff lecture slides\n",
    "        step_prev = self.step\n",
    "        self.step = (1 + np.sqrt(1 + 4*step_prev*step_prev))/2\n",
    "        self.momentum = (step_prev-1)/self.step\n",
    "        #print(f'\\t Now step={self.step}, momentum={self.momentum}')\n",
    "\n",
    "    def run_alg(self, x0):\n",
    "        x_curr = x0\n",
    "        z_curr = x0 \n",
    "        for i in range(self.max_iter):\n",
    "            #print(f'Before iter {i+1}, \\n \\t z = {z_curr}, x = {x_curr}')\n",
    "            self._update()\n",
    "            x_prev = x_curr\n",
    "            z_prev = z_curr\n",
    "            #compute new z_k and x_k\n",
    "            #print(x_curr.shape, z_curr.shape)\n",
    "            #print(self.grad(x_prev))\n",
    "            #print(x_prev - self.grad(x_prev))\n",
    "            z_curr = self.prox(x_prev - self.grad(x_prev))\n",
    "            #print(f'\\tIn iter {i+1}, grad calculated to be {self.grad(x_prev)}')\n",
    "            x_curr = z_curr + self.momentum * (z_curr - z_prev)\n",
    "            #x_curr = (1-self.momentum)*z_curr + self.momentum*z_prev\n",
    "            #print(f'In iter {i}, x_curr calculated to be {x_curr}')\n",
    "            #update momentum value for next iteration\n",
    "            #self._update()\n",
    "        return x_curr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "class A(LinearMap):\n",
    "    def __init__(self):\n",
    "        super().__init__([2], [2])\n",
    "        self.mat = torch.Tensor([[2,0],[0,1]])\n",
    "    def _apply(self, x):\n",
    "        return torch.matmul(self.mat,x)\n",
    "    def _apply_adjoint(self,x):\n",
    "        return self._apply(x)\n",
    "    \n",
    "class grad(LinearMap):\n",
    "    def __init__(self):\n",
    "        super().__init__([2],[2])\n",
    "        self._A = A()\n",
    "    def _apply(self, x):\n",
    "        y = self._A(x)\n",
    "        #print(y)\n",
    "        y -= torch.Tensor([2,1])\n",
    "        #print(y)\n",
    "        y = self._A(y)\n",
    "        return 2/17 * y #17 is needed to account for L lipshitz constant\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = FISTA(300, 1, None, grad(), prox.L1Regularizer(.001))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.9979, 0.9915])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.run_alg(torch.Tensor([5,5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70000\n",
      "7141\n",
      "6313\n",
      "13454\n"
     ]
    }
   ],
   "source": [
    "#Binary classification on MNIST digits using FISTA (specifically 3 and 6)\n",
    "#get dataset\n",
    "#uncomment to retech data\n",
    "X, y = fetch_openml('mnist_784', version=1, return_X_y=True, as_frame=False)\n",
    "y = y.astype(np.float64)\n",
    "X_orig, y_orig = X, y\n",
    "print(len(X))\n",
    "print(len(X[y==3]))\n",
    "print(len(X[y==5]))\n",
    "print(len(X[(y==3) | (y==5)]))\n",
    "\n",
    "def show_digit(X, y):\n",
    "    digit_image = X.reshape(28,28)\n",
    "    print(f'Expected digit {y+4}')\n",
    "    plt.imshow(digit_image, cmap=matplotlib.cm.binary, interpolation=\"nearest\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13454, 784) (13454,)\n",
      "Expected digit 5.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#reduce data to be binary classification for simplicity\n",
    "X, y = X[(y==3) | (y==5)], y[(y==3) | (y==5)]\n",
    "y = y - 4\n",
    "print(X.shape, y.shape)\n",
    "show_digit(X[0], y[0])\n",
    "#create train/test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=10000, test_size=3454)\n",
    "X_train, X_test, y_train, y_test = torch.from_numpy(X_train), torch.from_numpy(X_test), torch.from_numpy(y_train), torch.from_numpy(y_test)\n",
    "#let digit 3 = -1\n",
    "#let digit 6 = 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define grad callable\n",
    "X_train = X_train.type(torch.float32)\n",
    "X_test = X_test.type(torch.float32)\n",
    "y_train = y_train.type(torch.float32)\n",
    "y_test = y_test.type(torch.float32)\n",
    "def hubergrad(x, dh = .1):\n",
    "    if x >= 1:\n",
    "        return 0\n",
    "    elif x < 1 and x > 1 - dh:\n",
    "        return (x-1)/dh\n",
    "    else:\n",
    "        return -1\n",
    "class A(LinearMap):\n",
    "    def __init__(self):\n",
    "        self._A = X_train.clone()\n",
    "        for i in range(self._A.shape[0]):\n",
    "            self._A[i] *= y_train[i]\n",
    "        \n",
    "        super().__init__([28*28], [10000])\n",
    "    def _apply(self, x):\n",
    "        return torch.matmul(self._A, x)\n",
    "    def _apply_adjoint(self, x):\n",
    "        return torch.matmul(self._A.T, x)\n",
    "        \n",
    "class grad:\n",
    "    def __init__(self, dh=.1):\n",
    "        self.a = A()\n",
    "        self.L = 1/dh * torch.norm(self.a._A.T)\n",
    "        \n",
    "    def __call__(self, x):\n",
    "        x = self.a(x)\n",
    "        x = x.apply_(hubergrad)\n",
    "        x = self.a.adjoint(x)\n",
    "        x = 1/self.L * x\n",
    "        #print(x)\n",
    "        return x\n",
    "def eval(x):\n",
    "    res = torch.matmul(X_test, x)\n",
    "    res = torch.sign(res)\n",
    "    res *= y_test\n",
    "    print(f'Correct {res[res > 0].shape}')\n",
    "    print(f'Incorrect {res[res < 0].shape}')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = FISTA(50, 1, None, grad(), prox.L1Regularizer(.001))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = f.run_alg(torch.zeros(28*28, dtype=torch.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct torch.Size([3244])\n",
      "Incorrect torch.Size([210])\n"
     ]
    }
   ],
   "source": [
    "eval(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit (conda)",
   "language": "python",
   "name": "python38564bitcondac7010d5495f04ec788964219d36e608d"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
